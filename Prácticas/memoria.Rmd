---
title: "Memoria de las prácticas de Tratamiento Inteligente de Datos."
author: "Lidia Sánchez Mérida, Fernando Roldán Zafra."
date: "4/12/2019"
output:
  pdf_document:
    keep_tex: true
lang: es-ES
---
<!------------------------ PORTADA --------------------->
\thispagestyle{empty}

\begin{center} \huge \textbf{Tratamiento Inteligente de Datos} \end{center}
\vspace{0.3cm}
\begin{center} \Large \textbf{\textsc{Memoria de las prácticas de la asignatura}} \end{center}
\vspace{0.2cm}
\begin{center} \large \textbf{2019-2020} \end{center}

\vspace{2.5cm}

\hspace{8.5cm}{Lidia Sánchez Mérida.}

\vspace{0.15cm}

\hspace{8.5cm}{Fernando Roldán Zafra.}

\vspace{0.15cm}

\newpage
<!---------------- ÍNDICE DE CONTENIDOS ---------------->
\thispagestyle{empty}
\tableofcontents
\newpage
<!------------------------------------------------------>

# Exploración de datos del conjunto de entrenamiento original.

Este dataset que hemos seleccionado proporciona dos conjuntos, uno de entrenamiento y otro de prueba, en los que se recogen las opiniones de los pacientes, diagnosticados de una determinada enfermedad, acerca de los tratamientos que han probado. Existen dos tipos de opiniones, principalmente, una de ellas consiste en valorar el medicamento recetado para una enfermedad en concreto de 0 a 10. Por otro lado también se recopila, para cada opinión de un paciente, el número de personas que consideran que su crítica es útil. 

La elección de este dataset se fundamenta en diversos motivos. El más importante es que cumple con los requisitos establecidos por el profesor para, posteriormente, aplicar los algoritmos vistos en esta asignatura. Sin embargo, también tuvimos en cuenta la organización de competiciones de Machine Learning en las que se proponía este dataset como principal protagonista. 

Para comenzar con el estudio estadístico cargamos los datos de entrenamiento.
```{r lectura_datos, warning=FALSE}
# Cargamos la biblioteca que utilizaremos para graficar los datos estadísticos.
library(ggplot2)
# Cargamos los datos de entrenamiento y test
training_dataset <- read.csv(file="./drugsComTrain_raw.csv", header=TRUE, sep=",")
test_dataset <- read.csv(file="./drugsComTest_raw.csv", header=TRUE, sep=",")
```

A continuación presentamos las estadísticas que hemos pensado son más relevantes para nuestro dataset en particular. En primer lugar averiguamos las diez enfermedades más comunes que se encuentran registradas en nuestro conjunto de datos con el objetivo de visualizar aquellas dolencias que se presentan más frecuente en un centro sanitario.

```{r estadisticas}
# 1) Enfermedades más comunes.
# Extraemos un resumen acerca de las enfermedades registradas.
recuento_enfermedades<-summary(training_dataset$condition)
# Convertimos los resultados anteriores en una matriz para poder trabajar con ellos.
enfermedades_matriz<-data.matrix(recuento_enfermedades)
# Obtenemos los nombres de las dolencias.
enfermedades<-names(recuento_enfermedades)
# También obtenemos el número de muestras de cada enfermedad.
recuento<-enfermedades_matriz[1:length(enfermedades_matriz)]
# Componemos un data frame con las enfermedades y el número de muestras para cada una.
dataframe<-data.frame(enfermedades=enfermedades[1:10], recuento=recuento[1:10])
# Las representamos en un gráfico de barras.
ggplot(data=dataframe, aes(x=enfermedades, y=recuento)) + geom_bar(stat="identity")+coord_flip()+ggtitle('Enfermedades más comunes.')
```
Tal y como se puede comprobar que la enfermedad *Birth Control* es consideráblemente mayoritaria frente al número de muestras asociadas a las otras nueve enfermedades. Por ello, cuando reduzcamos nuestro conjunto de entrenamiento y test, deberemos tener en cuenta este aspecto de modo que todas las enfermedades escogidas tengan un número de muestras suficiente para ser representadas de forma equilibrada.

A continuación realizaremos el mismo experimento en relación a los medicamentos con el fin de conocer cuáles son los más recetados de forma general.

```{r estadisticas}
# 2) Medicamentos más comunes.
# Repetimos el procedimiento anterior para los medicamentos.
recuento_medicamentos<-summary(training_dataset$drugName)
medicamentos_matriz<-data.matrix(recuento_medicamentos)
medicamentos<-names(recuento_medicamentos)
recuento<-medicamentos_matriz[1:length(medicamentos_matriz)]
dataframe<-data.frame(medicamentos=medicamentos[1:10], recuento=recuento[1:10])
ggplot(data=dataframe, aes(x=medicamentos, y=recuento)) + geom_bar(stat="identity")+coord_flip()+ggtitle('Medicamentos más comunes.')
```

Una vez hemos exploradas las enfermedades y medicamentos más comunes, los dos siguientes datos estadísticos consisten en asociar estos dos factores con el objetivo de conocer qué medicamentos más comunes se encuentran asociados a una misma enfermedad y cuáles de las enfermedades más comunes se encuentran asociadas para un mismo medicamento. En esta tercera estadística nos ocuparemos del primer caso. 
```{r estadisticas}
# 3) Enfermedades comunes asociadas con un medicamento.
# Partimos del mismo calculo que en el apartado anterior donde obtenemos los medicamentos mas comunes
recuento_medicamentos<-summary(training_dataset$drugName)
matriz_medicamentos<-data.matrix(recuento_medicamentos)
medicamentos<-names(recuento_medicamentos)

# Creo un dataframe vacio donde meter los medicamentos mas comunes con sus enfermedades
dataframe_total<-data.frame()

# Bucle que itera sobre los 5 medicamentos más comunes
for(medicamento in medicamentos[1:5]){
  # Extraigo las filas del medicamento en cuestión
  df_medicamento<-training_dataset[training_dataset$drugName == medicamento, ]
  # Apunto el número de veces que se repite cada enfermedad
  recuento_enfermedades<-summary(df_medicamento$condition)
  # Transformo el dataframe a matriz
  enfermedades_matriz<-data.matrix(recuento_enfermedades)
  # Apunto el nombre de las enfermedades asociado al recuento de estas
  enfermedades<-names(recuento_enfermedades)
  # También obtenemos el número de muestras de cada enfermedad
  recuento<-enfermedades_matriz[1:length(enfermedades_matriz)]
  # Creo un dataframe computesto por las 5 enfermedades más comunes con su número 
  dataframe<-data.frame(enfermedades=enfermedades[1:5], recuento=recuento[1:5])
  # Creo el título del gráfico
  text <-(paste0('Enfermedades más comunes para ', medicamento))
  # Creo el gráfico para ese medicamento
  print(ggplot(data=dataframe, aes(x=enfermedades, y=recuento)) + geom_bar(stat="identity")+coord_flip()+ggtitle(text))
}

```

Como podemos comprobar, los cinco medicamentos más comunes son especialmente recetados para paliar la enfermedad denominada *Birth Control*. Del mismo modo podemos observar que el resto de dolcencias asociadas a estos cinco tratamientos también están especializados en casos relacionados con la contracepción así como enfermedades asociadas con la menstruación y los órganos genitales femeninos. Esto nos indica que diversos tipos de dolencias, principalmente femeninas, pueden tratarse con los mismos medicamentos puesto que son indicados para un conjunto específico de dolencias de esta naturaleza en particular. Asimismo, podemos afirmar que si bien hemos comprobado que la enfermedad representada con un mayor número de muestras es *Birth Control*, tiene sentido que los cinco medicamentos más comunes estén dedicados a paliar esta dolencia, que también es sumamente común. Por tanto, podemos afirmar la relación existente entre los medicamentos más ampliamente recetados con las dolencias más altamente registradas.
 
Para el siguiente caso realizaremos el mismo cálculo pero en orden inverso, es decir, comprobaremos cuáles son los medicamentos más comunes para una misma enfermedad. De este modo podremos observar los distintos tratamientos que se pueden aplicar a una misma enfermedad además de comprobar su popularidad a la hora de recetar cada uno de ellos.

```{r estadisticas}
# 4) Medicamentos para cada enfermedad más común.
# Realizamos el mismo calculo que en el apartado anterior pero adaptandolo al caso contrario
recuento_enfermedades<-summary(training_dataset$condition)
matriz_enfermedades<-data.matrix(recuento_enfermedades)
enfermedades<-names(recuento_enfermedades)

dataframe_total<-data.frame()
for(enfermedad in enfermedades[1:5]){
  df_enfermedades<-training_dataset[training_dataset$condition == enfermedad, ]
  recuento_medicamentos<-summary(df_enfermedades$drugName)
  medicamentos_matriz<-data.matrix(recuento_medicamentos)
  medicamentos<-names(recuento_medicamentos)
  recuento<-medicamentos_matriz[1:length(medicamentos_matriz)]
  dataframe<-data.frame(medicamentos=medicamentos[1:5], recuento=recuento[1:5])
  text <-(paste0('Medicamentos más comunes para ', enfermedad))
  print(ggplot(data=dataframe, aes(x=medicamentos, y=recuento)) + geom_bar(stat="identity")+coord_flip()+ggtitle(text))
}

```

En este caso, como se puede ver en las diferentes gráficas, los medicamentos se recetan de forma más distribuida, es decir para una misma enfermedad hay una mayor gama de tratamientos disponibles que se recetan con una frecuencia similar. Por lo tanto, no existen tratamientos recetados cláramente mayoritarios, como sucedía en el caso anterior.

En el siguiente dato estadístico estudiaremos la valoración de los medicamentos para cada una de las diez enfermedades más comunes con el objetivo de conocer la eficacia, según los pacientes, de los tratamientos que en general se recetan para cada dolencia. 

```{r estadisticas}
# 5) Eficacia general de los tratamientos recetados para las diez enfermedades más comunes.
# 5.1) Puntuación de los medicamentos asociados a "Birth Control".
# Extraemos un dataset solo con los registros asociados a la enfermedad en cuestión.
birth_control_dataset = subset(training_dataset, training_dataset$condition=="Birth Control")
# Calculamos variables estadísticas como la mediana, la media, el mínimo y máximo así como los cuartiles.
print("Estadísticas sobre los medicamentos para 'Birth Control'.")
summary(birth_control_dataset$rating)
# 5.2) Puntuación de los medicamentos asociados a "Depression".
depression_dataset = subset(training_dataset, training_dataset$condition=="Depression")
print("Estadísticas sobre los medicamentos para 'Depression'.")
summary(depression_dataset$rating)
# 5.3) Puntuación de los medicamentos asociados a "Pain".
pain_dataset = subset(training_dataset, training_dataset$condition=="Pain")
print("Estadísticas sobre los medicamentos para 'Pain'.")
summary(pain_dataset$rating)
# 5.4) Puntuación de los medicamentos asociados a "Anxiety".
anxiety_dataset = subset(training_dataset, training_dataset$condition=="Anxiety")
print("Estadísticas sobre los medicamentos para 'Anxiety'.")
summary(anxiety_dataset$rating)
# 5.5) Puntuación de los medicamentos asociados a "Acne".
acne_dataset = subset(training_dataset, training_dataset$condition=="Acne")
print("Estadísticas sobre los medicamentos para 'Acne'.")
summary(acne_dataset$rating)
# 5.6) Puntuación de los medicamentos asociados a "Bipolar Disorde".
bipolar_disorde_dataset = subset(training_dataset, training_dataset$condition=="Bipolar Disorde")
print("Estadísticas sobre los medicamentos para 'Bipolar Disorde'.")
summary(bipolar_disorde_dataset$rating)
# 5.7) Puntuación de los medicamentos asociados a "Insomnia".
insomnia_dataset = subset(training_dataset, training_dataset$condition=="Insomnia")
print("Estadísticas sobre los medicamentos para 'Insomnia'.")
summary(insomnia_dataset$rating)
# 5.8) Puntuación de los medicamentos asociados a "Weight Loss".
weight_loss_dataset = subset(training_dataset, training_dataset$condition=="Weight Loss")
print("Estadísticas sobre los medicamentos para 'Weight Loss'.")
summary(weight_loss_dataset$rating)
# 5.9) Puntuación de los medicamentos asociados a "Obesity".
obesity_dataset = subset(training_dataset, training_dataset$condition=="Obesity")
print("Estadísticas sobre los medicamentos para 'Obesity'.")
summary(obesity_dataset$rating)
# 5.10) Puntuación de los medicamentos asociados a "ADHD".
adhd_dataset = subset(training_dataset, training_dataset$condition=="ADHD")
print("Estadísticas sobre los medicamentos para 'ADHD'.")
summary(adhd_dataset$rating)
```
Como podemos comprobar en los resultados anteriores, si consideramos las medianas calculadas, es decir, la puntuación que se encuentra en la mitad del ranking, las enfermedades cuyos tratamientos, en general, son mejores valorados por los pacientes son *Pain, Anxiety, Acne, Weight Loss* y *Obesity*. Por el contrario, la que peor mediana tiene es *Birth Control*. Una de las ventajas de utilizar la mediana reside en la resistencia asociada a los valores de las puntuaciones, puesto que para calcularla lo único que se necesita es ordenar dichos valores y escoger el que se encuentra en la posición intermedia. Sin embargo, la media sí que se encuentra influida por los valores de las puntuaciones y, por lo tanto, se ve sesgada, principalmente, por los valores más bajos. Sin embargo, a través de esta variable estadística podemos confirmar las mismas conclusiones extraídas anteriormente, y además, nos permite agregar un mayor grado de concreción con respecto a los tratamientos mejor valorados. En este caso, podemos comprobar que la enfermedad cuyos tratamientos son mejor valorados es **Weight Loss, seguida de Obesity y Anxiety**.

A continuación procedemos cuáles son los medicamentos más efectivos, según la población, para estas tres enfermedades, con el objetivo de conocer las puntuaciones de los tratamientos que han provocado los buenos resultados observados anteriormente. Sin embargo, como el número de registros para cada una de las enfermedades es sumamente considerable, vamos a agregar una segunda condición. Esta trata de conseguir los medicamentos que a su vez son los más recetados. De este modo podremos conocer cuáles son los tratamientos más efectivos, según los pacients afectados por las tres enfermedades anteriores, además de los más comúnmente recetados. Con todos estos criterios los resultados, para esta dolencia en concreto, se pueden visualizar a continuación.

```{r estadisticas}
# 6) Medicamentos con mejores críticas y más veces recetados.
# 6.1) Para la primera enfermedad: 'Weight Loss'.
# Extraemos un dataset con las muestras asociadas solo a la enfermedad Weight Loss y con solamente los 
# medicamentos que tengan una valoración 10/10.
birth_control_dataset = subset(training_dataset, training_dataset$condition=="Weight Loss" & training_dataset$rating==10)
# Extraemos un resumen estadístico acerca de este pequeño dataset de Weight Loss.
recuento_medicamentos_weight_loss = summary(birth_control_dataset$drugName)
# Convertimos los datos a una matriz para poder trabajar con ellos.
medicamentos_matriz<-data.matrix(recuento_medicamentos_weight_loss)
# Obtenemos los nombres de los medicamentos para esta enfermedad en particular.
medicamentos<-names(recuento_medicamentos_weight_loss)
# Obtenemos el número de veces que han sido recetados cada uno de ellos.
recuento<-medicamentos_matriz[1:length(medicamentos_matriz)]
# Componemos un dataframe con estos últimos datos.
dataframe<-data.frame(medicamentos=medicamentos[1:10], recuento=recuento[1:10])
# Lo representamos mediante un gráfico de barras.
ggplot(data=dataframe,aes(x=medicamentos, y=recuento)) + geom_bar(stat="identity")+coord_flip()+ggtitle('Mejores medicamentos para "Weight Loss"')

# 6.2) Para la segunda enfermedad: 'Obesity'
obesity_dataset = subset(training_dataset, training_dataset$condition=="Obesity" & training_dataset$rating==10)
recuento_medicamentos_obesity = summary(obesity_dataset$drugName)
medicamentos_matriz<-data.matrix(recuento_medicamentos_obesity)
medicamentos<-names(recuento_medicamentos_obesity)
recuento<-medicamentos_matriz[1:length(medicamentos_matriz)]
dataframe<-data.frame(medicamentos=medicamentos[1:10], recuento=recuento[1:10])
ggplot(data=dataframe,aes(x=medicamentos, y=recuento)) + geom_bar(stat="identity")+coord_flip()+ggtitle('Mejores medicamentos para "Obesiy"')

# 6.3) Para la tercera enfermedad: 'Anxiety'
anxiety_dataset = subset(training_dataset, training_dataset$condition=="Anxiety" & training_dataset$rating==10)
recuento_medicamentos_anxiety = summary(anxiety_dataset$drugName)
medicamentos_matriz<-data.matrix(recuento_medicamentos_anxiety)
medicamentos<-names(recuento_medicamentos_anxiety)
recuento<-medicamentos_matriz[1:length(medicamentos_matriz)]
dataframe<-data.frame(medicamentos=medicamentos[1:10], recuento=recuento[1:10])
ggplot(data=dataframe,aes(x=medicamentos, y=recuento)) + geom_bar(stat="identity")+coord_flip()+ggtitle('Mejores medicamentos para "Anxiety"')

```
En el primer gráfico resultante podemos comprobar que existe un medicamento con una puntuación máxima y que, a su vez, es cláramente el más recetado denominado 'Phentermine/topiramate'. Por ello podemos determinar que en función de las críticas de los pacientes afectados por esta dolencia en concreto, este es el tratamiento mejor valorado y más comúnmente recetado.

No sucede lo mismo con el segundo gráfico en el que se muestran los diez medicamentos con una puntuación máxima y, a su vez, lo más recetados. En este caso existen dos tratamientos con un número bastante similar de recetas, por lo que podemos pensar que son los dos medicamentos más eficaces contra esta dolencia además de ser los dos más recetados. 

Por último, en el tercer gráfico podemos observar que se plantea la misma dinámica que en el primero, es decir, de nuevo existe un medicamento contra, en este caso, la ansiedad que tiene la mejor puntuación posible (10 de 10) y que es el más recetado.

# Preprocesamiento de los datos.

Realizando el análisis exploratorio anterior, nos percatamos de que existen **reviews repetidas para una misma enfermedad**. Creemos que es debido a que para una misma dolencia se han recetado varios medicamentos y cuando el paciente ha aportado su opinión, esta se ha asignado a cada uno de los tratamientos recetados para la misma enfermedad los cuales ocupan un registro distinto. Por ello, actualmente disponemos de reviews iguales para varias filas dentro del conjunto de datos de entrenamiento y de prueba, asociadas a una misma enfermedad y a los diversos tratamientos recetados para paliarla. Con el objetivo de poder aplicar, posteriormente, los algoritmos vistos en esta asignatura y así obtener resultados representativos, vamos a aplicar un procesamiento equivalente a eliminar aquellos registros que dispongan de la misma crítica tanto en el dataset de entrenamiento como en el de prueba. 

```{r procesamiento_datos}
## Conjunto de entrenamiento
# Eliminamos las filas que tengan la misma crítica.
new_training_dataset<-training_dataset[!duplicated(training_dataset$review), ]
# Comprobamos que no existen reviews repetidas.
reviews_repetidas<-new_training_dataset[duplicated(new_training_dataset$review)]
ncol(reviews_repetidas)

## Conjunto de prueba.
# Realizamos las mismas operaciones anteriores.
new_test_dataset<-test_dataset[!duplicated(test_dataset$review), ]
reviews_repetidas<-new_test_dataset[duplicated(new_test_dataset$review)]
ncol(reviews_repetidas)
```
Una vez hemos eliminado aquellos registros que disponen de la misma crítica, comenzaremos con el submuestreo del dataset para **reducir su tamaño**. Y es que, tal y como se ha podido comprobar en los resultados estadísticos anteriores, el número de muestras del conjunto de entrenamiento es bastante considerable. Asimismo, también hemos podido comprobar que existen clases de medicamentos con un número de muestras extremadamente mayoritario, como es *Birth Control*, por lo que no todas cuentan con la misma representación dentro del dataset. Es por ello por lo que, a continuación, se procede a aplicar un tratamiento consistente en reducir el conjunto de entrenamiento a 5.000 muestras. Para ello reduciremos el **número de enfermedades a 10 y para cada una de ellas obtendremos 500 muestras**. De este modo equilibramos las diversas clases de medicamentos existentes para, posteriormente, poder aplicar diversos algoritmos.

```{r procesamiento_datos}
## CONJUNTO DE ENTRENAMIENTO
# Obtenemos un resumen acerca de las enfermedades registradas en el dataset.
recuento_etiquetas<-summary(new_training_dataset$condition)
# Recopilamos los nombres de las enfermedades.
etiquetas<-names(recuento_etiquetas)
# Formamos un dataset más pequeño con las 10 enfermedades con mayor número de ejemplos y les asociamos 500 muestras para cada una.
n_enfermedades_max = 10
n_muestras_max = 500
# Primera enfermedad
mini_training_dataset <- head(subset(new_training_dataset, new_training_dataset$condition==etiquetas[1]), n_muestras_max)
# Resto de enfermedades
for (i in c(2:n_enfermedades_max)) {
  mini_training_dataset <- rbind(mini_training_dataset, head(subset(new_training_dataset,
    new_training_dataset$condition==etiquetas[i]), n_muestras_max))
}
# Desorganizamos los datos
set.seed(42)
rows<-sample(nrow(mini_training_dataset))
mini_training_dataset<-mini_training_dataset[rows,]

# Repetimos el proceso que se ha aplicado anteriormente para la obtención de ciertas estadísticas para comprobar que realmente el nuevo conjunto de entrenamiento reducido está balanceado.
recuento_enfermedades<-summary(mini_training_dataset$condition)
enfermedades_matriz<-data.matrix(recuento_enfermedades)
enfermedades<-names(recuento_enfermedades)
recuento<-enfermedades_matriz[1:length(enfermedades_matriz)]
dataframe<-data.frame(enfermedades=enfermedades[1:10], recuento=recuento[1:10])
ggplot(data=dataframe, aes(x=enfermedades, y=recuento)) + geom_bar(stat="identity")+coord_flip()+ggtitle('Clases de enfermedades del conjunto de entrenamiento.')
```

Como podemos comprobar en la gráfica anterior, en este dataset reducido ya no hay clases mayoritarias ni minoritarias, si no que todas disponen del mismo número de muestras representativas. Por lo tanto, hemos conseguido obtener un conjunto de datos de entrenamiento equilibrado con 5.000 muestras, es decir, 500 muestras para cada etiqueta que representa cada una de las diez enfermedades más comunes.

Del mismo modo procedemos con el **conjunto de prueba** de modo que también cuente con hasta 10 enfermedades diferentes con 500 muestras para cada una de ellas. Para ello repetiremos el mismo proceso anterior.

```{r procesamiento_datos}
## CONJUNTO DE PRUEBA
# Obtenemos un resumen acerca de las enfermedades registradas en el dataset.
recuento_etiquetas<-summary(new_test_dataset$condition)
# Recopilamos los nombres de las enfermedades.
etiquetas<-names(recuento_etiquetas)
# Formamos un dataset más pequeño con las 10 enfermedades con mayor número de ejemplos y les asociamos 500 muestras para cada una.
n_enfermedades_max = 10
n_muestras_max = 500
# Primera enfermedad
mini_test_dataset <- head(subset(new_test_dataset, new_test_dataset$condition==etiquetas[1]), n_muestras_max)
# Resto de enfermedades
for (i in c(2:n_enfermedades_max)) {
  mini_test_dataset <- rbind(mini_test_dataset, head(subset(new_test_dataset,
    new_test_dataset$condition==etiquetas[i]), n_muestras_max))
}
# Desorganizamos los datos
set.seed(42)
rows<-sample(nrow(mini_test_dataset))
mini_test_dataset<-mini_test_dataset[rows,]

# Repetimos el proceso que se ha aplicado anteriormente para la obtención de ciertas estadísticas para comprobar que realmente el nuevo conjunto de entrenamiento reducido está balanceado.
recuento_enfermedades<-summary(mini_test_dataset$condition)
enfermedades_matriz<-data.matrix(recuento_enfermedades)
enfermedades<-names(recuento_enfermedades)
recuento<-enfermedades_matriz[1:length(enfermedades_matriz)]
dataframe<-data.frame(enfermedades=enfermedades[1:10], recuento=recuento[1:10])
ggplot(data=dataframe, aes(x=enfermedades, y=recuento)) + geom_bar(stat="identity")+coord_flip()+ggtitle('Clases de enfermedades del conjunto de prueba.')
```

## Preprocesamiento de datos textuales.

En este subapartado procedemos a aplicar diversas técnicas para preparar los datos textuales, en especial las *reviews* de los pacientes, para que posteriormente podamos aplicar ciertos algoritmos con mayor facilidad. En primer lugar vamos a crear los vectores de documentos a partir de la columna anteriormente mencionada. Para ello convertiremos cada una de las críticas de los pacientes en un documento y las almacenaremos en un vector común. 

```{r corpus, warning=FALSE}
# Cargamos el paquete que nos permitirá aplicar ciertas operaciones sobre textos.
library("tm")
# Datos de entrenamiento.
# Obtenemos en forma de vector la columna de las reviews.
train_reviews<-as.vector(mini_training_dataset$review)
# Lo convertimos en un documento y lo almacenamos en el corpus que posteriormente crearemos.
train_reviews_corpus<-VectorSource(train_reviews)
train_reviews_corpus<-VCorpus(train_reviews_corpus)

# Datos de test.
test_reviews<-as.vector(mini_test_dataset$review)
test_reviews_corpus<-VectorSource(test_reviews)
test_reviews_corpus<-VCorpus(test_reviews_corpus)

# Mostramos algunos de los documentos obtenidos como ejemplo.
train_reviews_corpus[[5]]$content
```
Tal y como se puede observar, ahora cada una de las *reviews* de los pacientes se encuentra en un documento aparte, es decir, cada una de las opiniones de los pacientes ocupan una posición del vector de documentos. A continuación eliminaremos los **signos de puntuación** de las críticas porque, en principio, no nos aportan información relevante a la hora de aplicar técnicas relacionadas con la minería de textos. Asimismo, también hemos observado que ciertos signos de puntuación, como las comillas, no han sido procesados de forma adecuada y aparecen codificados como números. Obviamente este tipo de términos tampoco nos son útiles, por lo que procedemos, además, a **eliminar los números** de las críticas. Del mismo modo, con el objetivo de aplicar el mismo tratamiento a todas las palabras, procedemos también a **eliminar las mayúsculas**.

Por otro lado cabe destacar que para ciertas técnicas de análisis de textos, como podría ser encontrar los términos más comúnes, existen algunas palabras, en todos los idiomas, cuyo número de apariciones es súmamente considerable pero no aportan ningún tipo de información relevante. Este tipo de términos se pueden clasificar en preposiciones, artículos, entre otros, y en este ámbito se suelen conocer como **stop words**. En nuestro caso, como todas las *reviews* se encuentran en inglés, especificaremos dicho idioma para eliminar este tipo de términos de las críticas de los pacientes. Tras este procedimiento, los términos eliminados dejan espacios en blanco que también vamos a eliminar en este primer preprocesamiento de los datos textuales.

```{r preprocesamiento_textos}
# Cargamos la librería que nos permitirá aplicar ciertas técnicas de preprocesamiento de textos.
library(tm)
# Datos de entrenamiento.
# Eliminamos los signos de puntuación con la función tm_map indicándoselo como segundo argumento.
train_reviews_corpus<-tm_map(train_reviews_corpus, content_transformer(removePunctuation))
# Eliminamos los números.
train_reviews_corpus<-tm_map(train_reviews_corpus, content_transformer(removeNumbers))
# Eliminamos las mayúsculas.
train_reviews_corpus<-tm_map(train_reviews_corpus, content_transformer(tolower))
# Eliminamos los stopwords en inglés.
train_reviews_corpus<-tm_map(train_reviews_corpus, content_transformer(removeWords), stopwords("english"))
# Eliminamos los espacios en blanco sobrantes tras el anterior procedimiento,
train_reviews_corpus<-tm_map(train_reviews_corpus, content_transformer(stripWhitespace))

# Datos de prueba.
test_reviews_corpus<-tm_map(test_reviews_corpus, content_transformer(removePunctuation))
test_reviews_corpus<-tm_map(test_reviews_corpus, content_transformer(removeNumbers))
test_reviews_corpus<-tm_map(test_reviews_corpus, content_transformer(tolower))
test_reviews_corpus<-tm_map(test_reviews_corpus, content_transformer(removeWords), stopwords("english"))
test_reviews_corpus<-tm_map(test_reviews_corpus, content_transformer(stripWhitespace))

# Mostramos un ejemplo de preprocesamiento realizado.
train_reviews_corpus[[5]]$content
```
Como podemos observar, tras este primer preprocesamiento de las *reviews* de los pacientes se presentan textos en los que únicamente aparecen términos que tienen un mayor grado de relevancia para el estudio de este dataset en particular. No obstante, a consecuencia de eliminar palabras, pueden existir documentos sin contenido y por lo tanto no disponen de ninguna utilidad. Este será el siguiente procesamiento que aplicaremos a continuación: **eliminar los documentos vacíos.**
```{r preprocesamiento_textos}
# Datos de entrenamiento.
# Borraremos los documentos que estén vacíos. Para ello los tranformamos en una matriz de documentos.
train_reviews_matriz<-DocumentTermMatrix(train_reviews_corpus)
# Contamos el número de palabras de cada documento.
recuento_palabras<-apply(train_reviews_matriz, 1, sum)
# Comprobamos el número de documentos con 0 palabras.
cat("Documentos vacíos en el conjunto de entrenamiento:", recuento_palabras[recuento_palabras=0])

# Datos de prueba
test_reviews_matriz<-DocumentTermMatrix(test_reviews_corpus)
recuento_palabras<-apply(test_reviews_matriz, 1, sum)
cat("\nDocumentos vacíos en el conjunto de prueba", recuento_palabras[recuento_palabras=0])

# Estudio de la colección de documentos del conjunto de entrenamiento obtenida.
cat("\n\nEstudio de la colección de documentos del conjunto de entrenamiento tras el preprocesamiento.")
inspect(train_reviews_matriz)
```
Tal y como podemos comprobar, en nuestro caso, tras realizar el procedimiento por el cual eliminábamos palabras no relevantes, no existen documentos vacíos de contenido por lo que no podemos descartar ninguno. Asimismo, en función del estudio que se muestra a continuación acerca de la naturaleza de los documentos obtenidos del conjunto de entrenamiento, cabe destacar que se disponen de un total de 5.000 documentos y 11.825 términos. Sin embargo, en la lista de los términos más comunes podemos comprobar que algunos de ellos son variantes de otros, como por ejemplo son *take* y *taking*. Representa la misma información pero sin embargo se identifican como términos diferentes. Para eliminar este tipo de situaciones procedemos a aplicar una técnica conocida como **Lematización o Steaming**. Con ella se descartan aquellas palabras que tengan la misma raíz semántica y solo quedará un término de la misma familia. 

```{r preprocesamiento_textos}
# Datos de entrenamiento.
train_reviews_corpus<-tm_map(train_reviews_corpus, stemDocument)
train_reviews_matriz<-DocumentTermMatrix(train_reviews_corpus)
cat("Estudio de los documentos obtenidos tras el proceso de Lematización\n")
inspect(train_reviews_matriz)
# Datos de prueba.
test_reviews_corpus<-tm_map(test_reviews_corpus, stemDocument)
test_reviews_matriz<-DocumentTermMatrix(test_reviews_corpus)
```
Tras la aplicación de esta última técnica podemos comprobar que se ha producido una reducción razonable de términos pasando a tener menos de 8.500 en total. Asimismo, podemos observar una mejora en relación a los términos más frecuentes puesto que todos ellos son diferentes y por lo tanto todos pueden aportar información relevante a la hora de aplicar los sucesivos algoritmos a lo largo de este documento.

## Análisis de correlación.

En esta sección vamos a estudiar las relaciones que existen entre todas los campos de nuestro dataset para comprobar si algunos de ellos están correlacionados. Para ello vamos a convertir los atributos categóricos, como las enfermedades y los tratamientos, en valores numéricos sobre los que aplicar el estudio de la correlación. Sin embargo, campos como la fecha en la que se publicó la crítica del paciente así como esta misma, los vamos a omitir puesto que no tiene sentido intentar convertirlos en variables numéricas. 
```{r correlacion}
# Copio el dataset original en otro que modificaremos para este apartado.
df_corr<-mini_training_dataset
# Eliminamos los campos categóricos puesto que vamos a convertir sus valores en valores numéricos.
df_corr$drugName <- NULL
df_corr$condition <- NULL
# También eliminamos los campos review y date puesto que no los vamos a utilizar en esta sección.
df_corr$review<-NULL
df_corr$date<-NULL
# Conversión de las variables categóricas, que son enfermedades y tratamientos, a variables numéricas.
df_corr["condition"] <- transform(as.numeric(mini_training_dataset$condition))
df_corr["drugName"] <- transform(as.numeric(mini_training_dataset$drugName))
# Calculo la matriz de correlación para las variables numéricas.
matriz_correlacion<-cor(df_corr)#, method="spearman")
# Calculamos los gráficos de dispersión y los coeficientes de correlación.
library(PerformanceAnalytics)
chart.Correlation(df_corr, histogram = F, pch = 19)
# Graficamos los coeficientes de correlación para todas las variables evaluadas.
library(corrplot)
corrplot(matriz_correlacion, method="number", type="upper")
```
En la primera imagen podemos comprobar los coeficientes de correlación entre cada par de variables existentes junto con la confianza asociada a esta correlación, representando la máxima con tres estrellas. Tal y como podemos comprobar, las variables que se encuentran más relacionadas son *rating* y *usefulCount* aunque su valor al ser de 0.24 no es considerablemente significante como para establecer una relación de correlación. Asimismo, si bien podemos pensar que los campos asociados a las enfermedades y a los tratamientos podrían mostrar una asociación, como podemos observar, esta no se hace patente a la hora de convertir los valores categóricos a numéricos puesto que de este modo el algoritmo no es capaz de relacionar ambos conceptos.

En la segunda imagen podemos visualizar los coeficientes de correlación entre cada par de variables clasificados y coloreados en función de cuán fuerte es su asociación. Tal y como podemos comprobar, la relación de correlación más fuerte, y por ende, la que dispone de un color más definido, es la que hemos comentado anteriormente: *rating-usefulCount*. El resto de asociaciones no cuentan con valores significativos y por lo tanto, apenas son visibles en la gráfica.
  
## Análisis de la influencia de las variables.

A continuación comprobaremos la importancia de cada uno de los campos que se incluyen en nuestro dataset. El objetivo es utilizar, solamente, aquellas columnas que sean relevantes para el estudio de este dataset en particular. Comenzamos eliminando directamente la columna *uniqueID* en ambos conjuntos de datos puesto que no aporta ningún tipo de información relevante ya que solo representa el identificador único para cada una de los registros del dataset.
Del mismo modo también vamos a eliminar el campo en el que se recoge la fecha en la que se publicó la crítica puesto que tampoco nos aporta información útil para aplicar los sucesivos algoritmos.
```{r influencia_variables}
## CONJUNTO DE ENTRENAMIENTO
mini_training_dataset = mini_training_dataset[-1]
mini_training_dataset = mini_training_dataset[-5]

## CONJUNTO DE PRUEBA
mini_test_dataset = mini_test_dataset[-1]
mini_test_dataset = mini_test_dataset[-5]
```

# Análisis textual

Tal y como hemos comentado al comienzo de este documento, una de las columnas más relevantes de nuestro dataset es la denominada *review*, en la que los pacientes expresan su opinión acerca del tratamiento recetado para su dolencia en particular. Es por ello por lo que, tras preprocesar estas críticas, procedemos a analizar el contenido de las mismas con el objetivo de conocer cuáles son los términos más repetidos así como el contento o descontento de los pacientes con sus respectivos medicamentos.

## Nube de palabras

Una vez disponemos de los datos preprocesados, tanto asociados al conjunto de entrenamiento como al de prueba, procedemos a representar gráficamente los términos obtenidos de los diversos documentos mediante una primera **nube de palabras**, en la cual se ordenarán las palabras de las críticas de los pacientes en función de su número de apariciones. De este modo podremos conocer los términos más utilizados en las *reviews*. Estos serán representados en un mayor tamaño y se irá reduciendo conforme disminuya el número de veces que aparece cada uno de los términos.
```{r nube_palabras_apariciones}
library(wordcloud2)
library(knitr)
# Convertimos el corpus en una matriz de documentos cuyas filas serán los términos que aparecen en cada uno de ellos.
train_reviews_matriz_terminos<-as.matrix(TermDocumentMatrix(train_reviews_corpus))
# Ordenamos los términos en función de sus apariciones totales.
frecuencia_terminos<-sort(rowSums(train_reviews_matriz_terminos), decreasing=TRUE)
# Obtenemos un dataframe de los términos ordenados para poder representar la nube de palabras.
train_reviews_dataframe_ordenado<-data.frame(word=names(frecuencia_terminos), freq=frecuencia_terminos)
wordcloud2(train_reviews_dataframe_ordenado, size=1.2)
```
Tal y como podemos comprobar, la mayor parte de los términos más utilizados por los pacientes a la hora de expresar su opinión acerca de los fármacos recetados están directamente relacionados con el tiempo, como *day*, *year*, entre otros. Posteriormente, podemos observar un segundo grupo de palabras relacionadas con los sentimientos como *feel* o *pain*. Incluso podemos afirmar que dos de las enfermedades que se encuentran en nuestro dataset aparecen esta nube de palabras: *pain* y *anxieti*. Para estudiar más a fondo el contexto en el que se encuentran estos términos a continuación procedemos a analizar los sentimientos que se encuentran tras cada una de las críticas de los pacientes.

## Análisis de sentimientos

En esta sección trataremos de conocer el grado de satisfacción general de los pacientes con respecto a los tratamientos que se les han recetado para su dolencia particular. Para ello, en primer lugar, procedemos a realizar una análisis general que nos informe acerca de la tendencia global de las críticas. Para ello haremos uso del corpus extraido tras el preprocesamiento de las críticas y le aplicaremos el método ***analyzeSentiment*** de la biblioteca [*SentimentAnalysis*](https://cran.r-project.org/web/packages/SentimentAnalysis/vignettes/SentimentAnalysis.html)  con la cual obtendremos el tipo de sentimiento que se esconde tras cada una de las *reviews*: positivo, negativo o neutro. Para ello este tipo de biblioteca contiene una serie de diccionarios con los términos más relevantes para cada uno de los tres tipos de sentimientos. En nuestro caso particular utilizaremos el diccionario por defecto denominado *QDAP*.
```{r analisis_sentimientos, warning=false}
library(SentimentAnalysis)
# Obtenemos los sentimientos generales de las reviews
train_analisis_sentimientos<-convertToDirection(analyzeSentiment(train_reviews_corpus)$SentimentQDAP) 
# Obtenemos su resumen estadístico
resumen_analisis = summary(train_analisis_sentimientos)
# Dibujamos los resultados obtenidos
barplot(resumen_analisis, main = "Análisis de sentimientos de las reviews en train",
     xlab = "Tipo de sentimiento", ylab = "Nº de reviews", col = c("red3", "yellow2", "springgreen3"))
```
Como podemos observar en ambos gráficos la gran mayoría de las críticas muestran un **sentimiento positivo**, por lo que podemos deducir que de forma general los pacientes están satisfechos con los tratamientos que han sido recetados para sus respectivas enfermedades. Asimismo, cabe destacar la considerable diferencia entre el número de críticas positivas y negativas. Por último, las críticas asociadas a un sentimiento neutro se corresponden con el grupo minotiratio puesto que es entendemos que es bastante complicado proporcionar una opinión sin demostrar nuestros sentimientos acerca de un fármaco.

A continuación procedemos a profundizar más acerca de los resultados obtenidos anteriormente con el objetivo de conocer cuáles son los sentimientos concretos más comunes que los pacientes demuestran a la hora de opinar sobre sus respectivos tratamientos. Parar ello haremos uso de la librería *syuzhet*, y en concreto de la función *get_nrc_sentiment*, con la cual seremos capaces de medir el número de *reviews* que reflejan alguno de los ocho sentimientos posibles: enfado, expectación miedo, alegría, tristeza, confianza, sorpresa.

```{r analisis_sentimientos, warning=false}
library(syuzhet)
library("tm")
library(ggplot2)
# Obtenemos el corpus de los comentarios de los pacientes ya preprocesados.
train_reviews_corpus2<-Corpus(VectorSource(train_reviews))
# Realizamos este nuevo análisis de sentimientos.
analisis_sentimientos2<-get_nrc_sentiment(train_reviews_corpus2$content)
# Representamos gráficamente los resultados ordenados de menor a mayor en función del porcentaje de críticas que se corresponden con cada sentimiento
library(RColorBrewer)
colores<-brewer.pal(8, "Set2")
barplot(sort(colSums(prop.table(analisis_sentimientos2[, 1:8]))), las=2, col=colores)
```
Tal y como podemos comprobar el sentimiento que predomina en las críticas de los pacientes es la confianza, seguido de un segundo sentimiento negativo que es la tristeza y de un tercero que es la expectación. Estos resultados pueden explicar el comportamiento de los seres humanos ante una enfermedad, y es que al ser diagnosticados es normal que sintamos tristeza por la situación actual y por la temporada que nos espera de tratamiento. Asimismo, también es razonable sentir confianza en los fármacos recetados por los especialistas en medicina para tratar nuestra dolencia y que nos hagamos ciertas expectativas acerca de la efectividad del mismo.

# Ténicas de Regresión

## Regresión lineal simple.

En esta sección aplicaremos la **regresión lineal simple** consistente en generar un modelo de predicción que permita averiguar el valor de una determinada variable numérica en función de otra del mismo tipo. Para aplicar esta técnica vamos a añadir una nueva columna de clasificación binaria a nuestro dataset convirtiendo las puntuaciones de los medicamentos, que se encuentran en un rango entre 0 y 10, a dos valores binarios que representen la efectividad del tratamiento. El intervalo [0,4] corresponderá al valor 0 y por lo tanto representará que para un paciente en particular el medicamento no ha sido de ayuda, mientras que el intervalo [5-10] se corresponderá con el valor 1 que representará la eficacia del tratamiento.

A continuación entrenamos un modelo de regresión simple cuya variable dependiente será el campo ratingBinaryLabel y la variable predictora será la categoría que contiene las puntuaciones originales de los tratamientos: rating. 

```{r regresion_lineal_simple}
# Recorremos las filas del conjunto de entrenamiento y comprobamos los valores en los intervalos definidos.
for (i in 1:length(mini_training_dataset$rating)){
  if (mini_training_dataset$rating[i] < 5)
    mini_training_dataset$ratingLabel[i]<-0
  else
    mini_training_dataset$ratingLabel[i]<-1
}
# Realizamos el mismo procedimiento para el conjunto de test.
for (i in 1:length(mini_test_dataset$rating)){
  if (mini_test_dataset$rating[i] < 5)
    mini_test_dataset$ratingLabel[i]<-0
  else
    mini_test_dataset$ratingLabel[i]<-1
}

# Especificamos la variable a predecir, que en nuestro caso será el campo binario relacionado con la efectividad del tratamiento, y la variable predictora que se corresponde con el campo de las puntuaciones originales de los medicamentos.
modelo = mini_training_dataset$ratingLabel ~ mini_training_dataset$rating
# Entrenamos el modelo.
regresion_lineal = lm(modelo, mini_training_dataset)
# Comprobamos los resultados del modelo.
summary(regresion_lineal)
```
Tal y como podemos comprobar en el resumen estadístico mostrado en primer lugar, el modelo predictivo es confiable en tanto en cuanto su p-value tanto en el origen como en la pendiente es menor que 0.05. Además, observando el valor del atributo *Multiple R^2* podemos determinar que el modelo es capaz de predecir hasta un 80% de valores del campo *ratingLabel* mediante el atributo *rating*. Para ello aplica la siguiente ecuación, que se obtiene del *intercepto* y de la pendiente calculados préviamente: `rating_binario = -0.0684667 + 0.1173970 * rating_original`. Su interpretación reside en que por cada incremento en una unidad de la variable *rating* se corresponde a 0.117 del valor de *ratingLabel*. 

Sin embargo, para medir la bondad del modelo de una forma más precisa y tradicional, procedemos a definir la siguiente función que es capaz de calcular las predicciones realizadas por el modelo entrenado préviamente, tanto para el conjunto de entrenamiento como para el de test, para posteriormente calcular ambas **tasas de error**. Encapsulamos el código referente a este procedimiento en una función puesto que así podremos reutilizarlo más adelante en los sucesivos modelos de regresión que aplicaremos a nuestro dataset.

```{r regresion_lineal_simple}
# Función que recibe el modelo de regresión entrenado para realizar las predicciones tanto del conjunto de prueba como del conjunto de entrenamiento y calcula ambas tasas de error. 
evaluar_modelo_regresion<-function(modelo) {
  # Calculamos la probabilidad de cada muestra de pertenecer a una clase u a otra.
  train_probab<-predict(modelo, mini_training_dataset, type="response")
  test_probab<-predict(modelo, mini_test_dataset, type="response")
  # Inicializamos todas las etiquetas a 0.
  train_predicc<-rep(0, length(train_probab))
  test_predicc<-rep(0, length(test_probab))
  
  # En función de las probabilidades calculadas anteriormente clasficaremos el resto de muestras pertenecientes a la clase cuya etiqueta binaria es 1. Para ello consideramos que una muestra pertenece a esta clase si su probabilidad es mayor o igual a 0.5.
  train_predicc[train_probab >= .5] = 1
  test_predicc[test_probab >= .5] = 1
  # Mostramos la matriz de confusión que nos aportará más información acerca de los falsos positivos.
  cat("Matriz de confusión.\n")
  print(table(pred=test_predicc, real=mini_test_dataset$ratingLabel))
  
  # Ahora calculamos la tasa de error en % para cada conjunto.
  train_error = mean(train_predicc != mini_training_dataset$ratingLabel)
  test_error = mean(test_predicc != mini_test_dataset$ratingLabel)
  cat("\nTasa de error en entrenamiento:",train_error*100,"%")
  cat("\nTasa de error en prueba:",test_error*100,"%")
} 

evaluar_modelo_regresion(regresion_lineal)
```
Tal y como podemos comprobar, la **tasa de error sobre el conjunto de entrenamiento**, como era de esperar es bastante pequeña. Sin embargo, el hecho de que sea 0% no es favorable puesto que, por el contrario, **el error en el conjunto de prueba** es considerablemente alto, por lo tanto podemos reflexionar acerca de si el modelo se ha ajustado demasiado a los datos de entrenamiento y por ello su capacidad de generalización es menor. 
Asimismo, si analizamos la matriz de confusión, podemos comprobar que existe una alta tasa de errores al clasificar muestras en la categoría 1 mientras que en realidad pertenecen a la clase cuya etiqueta es 0, y viceversa. Con el objetivo de evaluar la calidad del modelo entrenado procedemos a representar la **curva ROC** así como estimar el área existente debajo de la misma.
```{r regresion_lineal_simple}
# Función que realiza las predicciones con la función del paquete asociado a la curva ROC para posteriormente pintarla.
library("ROCR")
curvaROC<-function(modelo, etiquetas) { 
  # Obtenemos las predicciones.
  predicciones<-prediction(modelo, etiquetas)
  # Calculamos el rendimiento del modelo teniendo en cuenta los falsos positivos y los aciertos.
  curva<-performance(predicciones, "tpr", "fpr")
  # Dibujamos la curva.
  plot(curva, col="green", add=FALSE, main="Curva ROC. Regresión Lineal.", lwd = 2) 
  segments(0, 0, 1, 1, col='black')
  grid() 
  # Calculamos el área debajo de la curva
  curva.area = performance(predicciones, "auc")
  cat("\nEl área bajo la curva ROC es", curva.area@y.values[[1]]*100,"%\n")
}

# Curva ROC para el conjunto de prueba
test_probab = predict(regresion_lineal, mini_test_dataset, type=c("response"))
curvaROC(test_probab, mini_test_dataset$ratingLabel)
```
Como podemos comprobar la curva ROC es prácticamente lineal y por ende el área bajo ella es bastante escasa. Este aspecto nos indica que la capacidad de generalización del modelo entrenado es bastante escasa, con lo que explica la tasa de error tan elevada sobre el conjunto de prueba que hemos obtenido préviamente. 

### Regresión lineal robusta

En esta subsección trataremos de entrenar un modelo predictivo lineal utilizando, para ello, una subtécnica de la anterior denominada **regresión robusta**. Esta técnica presenta ciertas ventajas como la independencia a los *valores atípicos*, los cuales son datos que no siguen el patrón del resto y por lo tanto sus valores son muy dispares. Con este modelo pretendemos mejorar los resultados del anterior así como obtener tasas de error más confiables y robustas. 

```{r regresion_lineal_robusta}
# Cargamos la librería que nos permitirá entrenar un modelo con esta técnica.
library(MASS)
# Entrenamos el modelo.
modelo = mini_training_dataset$ratingLabel ~ mini_training_dataset$rating
regresion_robusta = rlm(modelo, mini_training_dataset)
# Obtenemos un resumen estadístico acerca del modelo entrenado.
summary(regresion_robusta)
# Comprobamos la tasa de error sobre el conjunto de entrenamiento y de prueba.
evaluar_modelo_regresion(regresion_robusta)
# Dibujamos su curva ROC
test_probab = predict(regresion_robusta, mini_test_dataset, type=c("response"))
curvaROC(test_probab, mini_test_dataset$ratingLabel)
```
Tal y como podemos observar en los resultados, el modelo entrenado con *regresión lineal robusta* no proporciona una mejora significativa puesto que tanto las tasas de error sobre ambos conjuntos como el área de la curva ROC siguen indicando que el modelo dispone de una capacidad de generalización bastante escasa. Por lo tanto, podemos concluir que para nuestro dataset un modelo entrenado mediante regresión lineal simple para predecir la efectividad de los tratamientos en función de su puntuación original, no es aconsejable puesto que no llega a tener una buena capacidad de predicción.

## Regresión logística simple

Aplicaremos esta técnica con el objetivo de entrenar un modelo predictivo capaz de averiguar, para cada muestra, la clase binaria a la que pertenece el tratamiento: 0 (no efectivo) o 1 (efectivo). Para ello se realizará un procedimiento similar al anterior solo que en este caso utilizaremos la función correspondiente a la **regresión logística** para llevar a cabo el entrenamiento del sistema. 

```{r regresion_logistica}
# Entrenamos un modelo predictivo con regresión logística. Para ello especificamos como variable dependiente la que deseamos predecir, que en nuestro caso será ratingLabel, y como variable predictora la puntuación original en el intervalo [0, 10].
regresion_logistica = glm(ratingLabel~rating, family=binomial(logit), data=mini_training_dataset)
# Resumen acerca del modelo entrenado.
summary(regresion_logistica)
# Evaluación del modelo entrenado.
evaluar_modelo_regresion(regresion_logistica)
```
Tal y como podemos comprobar el modelo entrenado con la técnica actual no es confiable puesto que ambos campos tienen un p-value muy cercano a 1, por lo que podemos concluir que no puede ser predicha la etiqueta binaria mediante las puntuaciones originales de forma lineal.

## Regresión polinomial

Si bien los resultados de los modelos predictivos entrenados mediante técnicas lineales no han sido buenos, vamos a aplicar una técnica no lineal con el objetivo de comprobar si la varible binaria *ratingLabel* puede ser predicha mediante modelo polinómico. Para aplicar esta técnica es indispensable incluir algunos componentes no  lineales, como pueden ser nuevos predictores obtenidos a partir de aplicar técnicas sobre los originales como elevarlos a una potencia. Comenzaremos utilizando un polinomio de grado 2, para lo que necesitaremos incluir la variable *rating*, con la que intentamos predecir la clase a la que pertenece cada tratamiento, elevada al cuadrado de la siguiente forma.
```{r regresion_polinomial}
# Entrenamos el modelo con regresión polinomial estableciendo un polinomio de grado 2.
regresion_polinomica = lm(formula=ratingLabel~poly(rating, 2), data=mini_training_dataset)
# Estudiamos el modelo entrenado.
summary(regresion_polinomica)
# Calculamos las tasas de error sobre entrenamiento y prueba.
evaluar_modelo_regresion(regresion_polinomica)
```

Como podemos observar en el estudio del modelo entrenado los *p-values* de todos los componentes son bastante bajos por lo que podemos determinar que este nuevo modelo predictivo es confiable y es suficiente utilizar un polinomio de orden 2. Asimismo también podemos concluir que la variable *rating* está relacionada con la que intentamos predecir: *ratingLabel*. También podemos comprobar una mejoría sobre los resultados mostrados en la matriz de confusión puesto que el número de muestras erróneamente clasificadas ha descendido considerablemente, comparado con los anteriores modelos lineales. Este mismo hecho se demuestra al evaluar el modelo predictivo y obtener las tasas de error tanto en el conjunto de entrenamiento como en el de prueba, ya que como podemos observar, los errores entran dentro de un rango razonable. 

A continuación procedemos a representar gráficamente la curva que describe el polinomio calculado para entrenar dicho modelo. Para ello, en primer lugar, debemos de obtener las predicciones para la etiqueta binaria mediante la interpolación de puntos dentro del rango del campo predictor. A mayor número de puntos, más precisa será la representación gráfica.

```{r regresion_polinomial}
# Interpolación de puntos dentro del rango del campo rating
rango<-range(mini_training_dataset$rating)
puntos<-seq(from=rango[1], to=rango[2], by=1)
puntos<-data.frame(rating=puntos)
# Predicción de la etiqueta binaria y cálculo del error estándar del modelo. Para ello se establece un 95% de confianza.
predicciones<-predict(regresion_polinomica, newdata=puntos, se.fit=TRUE, level=0.95)
# Cálculo del intervalo de confianza superior e inferior al 95%.
intervalo_confianza<-data.frame(inferior=predicciones$fit-1.96*predicciones$se.fit, superior=predicciones$fit+1.96*predicciones$se.fit)
attach(mini_training_dataset)
plot(x=rating, y=ratingLabel, pch = 20, col = "darkgrey")
title("Polinomio de grado 2: ratingLabel~rating.")
lines(x = puntos$rating, predicciones$fit, col = "red", pch = 20)
lines(x = puntos$rating, intervalo_confianza$inferior, col = "blue", pch = 4)
lines(x = puntos$rating, intervalo_confianza$superior, col = "blue", pch = 4)
```
En esta gráfica queda cláramente representada la relación existente entre la variable *rating* y la etiqueta binaria que deseamos predecir *ratingLabel*. Esta relación consiste en que a mayor puntuación, mayor es la efectividad del tratamiento y por lo tanto se encuentra dentro de la categorái de medicamentos efectivos. 

En base a los estudios realizados con diversas variantes de la regresión, podemos determinar que la **regresión polinómica** ha sido el único con el que hemos obtenido un modelo competitivo, confiable y capaz de clasificar correctamente los tratamientos en efectivos o no efectivos en base a la puntuación, entre 0 y 10, asociada por cada uno de los pacientes afectados. Con ello podemos concluir que nuestro problema **no es lineal*, y por lo tanto no se puede entrenar un modelo lineal para realizar una buena predicción

# Reglas de asociación

En esta técnica se pretende realizar un análisis acerca de uno de los campos más relevantes del dataset, a nuestro parecer: las *reviews* de los pacientes. Aplicando este procedimiento sobre nuestro conjunto de datos pretendemos extraer las relaciones existentes entre las palabras contenidas en estas críticas que redactan los enfermos asociadas a una determinada enfermedad y a uno o varios tratamientos. De este modo podremos conocer los términos más comunes asociados a cada una de los medicamentos recetados.
